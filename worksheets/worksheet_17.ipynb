{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 17\n",
    "\n",
    "Name:  \n",
    "UID: \n",
    "\n",
    "### Topics\n",
    "\n",
    "- Linear Model Evaluation\n",
    "\n",
    "## Linear Model Evaluation\n",
    "\n",
    "a) Assume your model is $$y = \\beta_0 + \\beta_1 x $$\n",
    "\n",
    "Show that TSS = RSS + ESS using the fact that we are at the minimum of RSS (i.e. when its derivative wrt either paramter is equal to zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Plot a data set and fitted line through the point when there is no relationship between X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLE_SIZE = 10\n",
    "\n",
    "xlin = -1.0 + 1.0 * np.random.random(SAMPLE_SIZE)\n",
    "y = ... + np.random.randn(SAMPLE_SIZE)\n",
    "\n",
    "intercept = np.ones(np.shape(xlin)[0])\n",
    "X = np.array([intercept, xlin]).T\n",
    "beta = ...\n",
    "\n",
    "xplot = np.linspace(-1,1,20)\n",
    "yestplot = ...\n",
    "plt.plot(xplot, yestplot,'b-',lw=2)\n",
    "plt.plot(xlin, y,'ro',markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using the above code, plot a histogram of the parameter estimates for the slope after generating `1000` independent datasets. Comment on what the plot means. Increase the sample size to see what happens to the plot. Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hist = []\n",
    "for _ in range(1000):\n",
    "    ...\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(..., bins=100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) We know that:\n",
    "\n",
    "$$\\hat\\beta-\\beta \\sim \\mathcal{N}(0,\\sigma^2 (X^TX)^{-1})$$\n",
    "\n",
    "thus for each component $k$ of $\\hat\\beta$ (here there are only two - one slope and one intercept)\n",
    "\n",
    "$$\\hat\\beta_k -\\beta_k \\sim \\mathcal{N}(0, \\sigma^2 S_{kk})$$\n",
    "\n",
    "where $S_{kk}$ is the $k^\\text{th}$ diagonal element of $(X^TX)^{-1}$. Thus, we know that \n",
    "\n",
    "$$z_k = \\frac{\\hat\\beta_k -\\beta_k}{\\sqrt{\\sigma^2 S_{kk}}} \\sim \\mathcal{N}(0,1)$$\n",
    "\n",
    "Verify that this is the case through a simulation and compare it to the standard normal pdf by plotting it on top of the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "beta_hist = []\n",
    "for _ in range(1000):\n",
    "    ...\n",
    "\n",
    "xs = np.linspace(-10,10,1000)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(beta_hist, bins=100, density=True)\n",
    "ax.plot(xs, norm.pdf(...), color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Above we normalized $\\hat\\beta$ by subtracting the mean and dividing by the standard deviation. While we know that the estimate of beta is an unbiased estimator, we don't know the standard deviation. So in practice when doing a hypothesis test where we want to assume that $\\beta = 0$, we can simply use $\\hat\\beta$ in the numerator. However we don't know the standard deviation and need to use an unbiased estimate of the standard deviation instead. This estimate is the standard error `s`\n",
    "\n",
    "$$s = \\sqrt{\\frac{RSS}{n - p}}$$\n",
    "\n",
    "where p is the number of parameters beta (here there are 2 - one slope and one intercept). This normalized $\\hat\\beta$ can be shown to follow a t-distribution with `n-p` degrees of freedom. Verify this is the case with a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "def standard_error(ytrue, ypred):\n",
    "    ...\n",
    "\n",
    "beta_hist = []\n",
    "for _ in range(1000):\n",
    "    ...\n",
    "\n",
    "xs = np.linspace(-10,10,1000)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(beta_hist, bins=100, density=True)\n",
    "ax.plot(xs, t.pdf(xs, SAMPLE_SIZE - 2), color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) You are given the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-0.1920605, -0.11290798, -0.56434374, -0.67052057, -0.19233284, -0.42403586, -0.8114285, -0.38986946, -0.37384161, -0.50930229])\n",
    "y = np.array([-0.34063108, -0.33409286, 0.34245857, 0.11062295, 0.76682389, 0.86592388, -1.68912015, -2.01463592, 1.61798563, 0.60557414])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is the probability of observing a dataset at least as extreme as the above assuming $\\beta = 0$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
