{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 11\n",
    "\n",
    "Name:  Daniel Scrivener\n",
    "UID: U38208685\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "|-------------|-------------|-------------|-------|\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(Attribute A = Yes | Class = No) = 3 / 7\n",
    "- P(Attribute B = Divorced | Class = Yes) = 1 / 3\n",
    "- P(Attribute C = High | Class = No) = 3 / 7\n",
    "- P(Attribute C = Mid | Class = Yes) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (Yes, Married, Mid)\n",
    "\n",
    "    For Class = No:\n",
    "        (3/7) * (4/7) * (1/7)\n",
    "\n",
    "    For Class = Yes:\n",
    "        (0/3) * (0/3) * (3/3)\n",
    "\n",
    "    -> Predict \"No\"\n",
    "- (No, Divorced, High)\n",
    "\n",
    "    For Class = No:\n",
    "        (4/7) * (1/7) * (3/7)\n",
    "\n",
    "    For Class = Yes:\n",
    "        (3/3) * (1/3) * (0/3)\n",
    "\n",
    "    -> Predict \"No\"\n",
    "- (No, Single, High)\n",
    "\n",
    "    Impossible to get Yes due to \"High\"\n",
    "\n",
    "    -> Predict \"No\"\n",
    "- (No, Divorced, Low)\n",
    "    Impossible to get Yes due to \"Low\"\n",
    "    \n",
    "    -> Predict \"No\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "def confusion_matrix(actual, predicted):\n",
    "    compare = zip(actual, predicted)\n",
    "    match_yes = 0\n",
    "    match_no = 0\n",
    "    yes_when_no = 0\n",
    "    no_when_yes = 0\n",
    "    for comp in compare:\n",
    "        if comp[0] == comp[1]:\n",
    "            if comp[0] == \"Yes\":\n",
    "                match_yes += 1\n",
    "            else:\n",
    "                match_no += 1\n",
    "        else:\n",
    "            if comp[0] == \"Yes\":\n",
    "                no_when_yes += 1\n",
    "            else:\n",
    "                yes_when_no += 1\n",
    "        \n",
    "    mat = np.zeros((2,2), dtype=np.int32)\n",
    "    mat[0,0] = match_yes\n",
    "    mat[1,1] = match_no\n",
    "    mat[0,1] = no_when_yes\n",
    "    mat[1,0] = yes_when_no\n",
    "    return mat\n",
    "\n",
    "\n",
    "print(confusion_matrix(actual_class, predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "|------------|---------------|---------------|\n",
    "| actual = Y |       -1      |       5       |\n",
    "| actual = N |        10     |       0       |\n",
    "\n",
    "What is the cost of the above classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(-1) * 2 + 5 * 1 + 10 * 3 + 0 * 4 = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "def calc_cost(actual, predicted, cost_mat):\n",
    "    conf_mat = confusion_matrix(actual, predicted)\n",
    "    sum = 0\n",
    "    for row in range(conf_mat.shape[0]):\n",
    "        for col in range(conf_mat.shape[1]):\n",
    "            sum += conf_mat[row][col] * cost_mat[row][col]\n",
    "\n",
    "    return sum\n",
    "\n",
    "cost_mat = np.array([[-1,5],[10,0]])\n",
    "\n",
    "print(calc_cost(actual_class, predicted_class, cost_mat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement functions for the following:\n",
    "\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f-measure\n",
    "\n",
    "and apply them to the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 0.4\n",
      "Recall: 0.6666666666666666\n",
      "F-Measure: 0.5\n"
     ]
    }
   ],
   "source": [
    "# precision = a / (a + c)\n",
    "# recall = a / (a + b)\n",
    "# f-score = 2RP / (R + P)\n",
    "\n",
    "def accuracy(actual, predicted):\n",
    "    conf_mat = confusion_matrix(actual, predicted)\n",
    "    return (conf_mat[0][0] + conf_mat[1][1]) / np.sum(conf_mat)\n",
    "\n",
    "def precision(actual, predicted):\n",
    "    conf_mat = confusion_matrix(actual, predicted)\n",
    "    return conf_mat[0][0] / (conf_mat[0][0] + conf_mat[1][0])\n",
    "\n",
    "def recall(actual, predicted):\n",
    "    conf_mat = confusion_matrix(actual, predicted)\n",
    "    return conf_mat[0][0] / (conf_mat[0][0] + conf_mat[0][1])\n",
    "\n",
    "def f_measure(actual, predicted):\n",
    "    p = precision(actual, predicted)\n",
    "    r = recall(actual, predicted)\n",
    "    return (2 * r * p) / (r + p)\n",
    "\n",
    "print(\"Accuracy:\", str(accuracy(actual_class, predicted_class)))\n",
    "print(\"Precision:\", str(precision(actual_class, predicted_class)))\n",
    "print(\"Recall:\", str(recall(actual_class, predicted_class)))\n",
    "print(\"F-Measure:\", str(f_measure(actual_class, predicted_class)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d33d6f76413f5831fcfd3d2ddd9466b21096f7dfcc99d9cf60fb20dd3aed122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
